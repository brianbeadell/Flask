{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece16f2a",
   "metadata": {},
   "source": [
    "# Mushroom Classifier\n",
    "\n",
    "\n",
    "## Name: Brian Beadell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1155b4b",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In my analysis, I aimed to predict whether mushrooms are edible or poisonous based on their features. I started by exploring the dataset's structure and preprocessing it to handle missing values and encode categorical variables. I used the KNeighborsClassifier algorithm to impute missing values, particularly in the \"stalk-root\" feature. For model training, I employed both RandomForestClassifier and LogisticRegression models on the preprocessed dataset, using one-hot encoding for features and label encoding for the response variable. To evaluate model performance, I considered metrics such as accuracy, precision, recall, and computational time. Key findings shed light on mushroom classification insights and their implications across various domains. Challenges encountered included dealing with missing data and computational constraints, which I addressed through thorough preprocessing and model exploration. Moving forward, I suggest refining models, exploring new techniques, and collaborating with domain experts for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46904c49",
   "metadata": {},
   "source": [
    "In this section, I import the libraries required for the analysis. I start with pandas and numpy for data manipulation and numerical operations, respectively. Then, I import various modules from scikit-learn, including train_test_split for splitting the data, KNeighborsClassifier for implementing the K-Nearest Neighbors algorithm, OneHotEncoder and LabelEncoder for encoding categorical features, Counter for counting occurrences, RandomForestClassifier and LogisticRegression for training classification models, and accuracy_score, precision_score, and recall_score for evaluating model performance. Finally, I import PCA for performing Principal Component Analysis. These libraries are essential for data preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325ea205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878de8ab",
   "metadata": {},
   "source": [
    "In this code, I'm defining a list named columns containing the names of the features present in a dataset related to mushrooms. These features include attributes like cap shape, color, odor, and more. By explicitly listing these column names, I aim to ensure that when I load the dataset using Pandas `read_csv` function, each attribute is correctly labeled. Additionally, I'm specifying the na_values parameter to handle missing values denoted by '?' in the dataset. This step is crucial for data preprocessing, as it allows me to effectively handle missing data during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ac9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "columns = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor',\n",
    "           'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape',\n",
    "           'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
    "           'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color',\n",
    "           'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51f9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('agaricus-lepiota.data', header=None, names=columns, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76c0c2",
   "metadata": {},
   "source": [
    "In this section, I'm addressing missing data in the dataset related to mushrooms. First, I'm identifying instances where the 'stalk-root' feature contains missing values and storing them in a DataFrame named missing_data. Then, I'm creating a DataFrame named present_data by removing rows with missing values in the 'stalk-root' feature.\n",
    "\n",
    "After handling missing data, I'm defining the features and labels for the analysis. The features `X_present` consist of all columns except 'stalk-root', while the labels `y_present` correspond to the 'stalk-root' feature from the cleaned dataset. This separation enables me to prepare the data for further analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e13677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data\n",
    "missing_data = data[data['stalk-root'].isna()]\n",
    "present_data = data.dropna(subset=['stalk-root'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73872cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and labels\n",
    "X_present = present_data.drop(columns=['stalk-root'])\n",
    "y_present = present_data['stalk-root']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c85565",
   "metadata": {},
   "source": [
    "This section handles encoding for categorical features. OneHotEncoder converts categorical features in `X_present` into binary vectors, while LabelEncoder encodes labels in `y_present`. After encoding, the data is split into training and test sets for model validation, with 80% for training and 20% for testing, ensuring the model's generalization ability is assessed on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd58dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_present_enc = enc.fit_transform(X_present)\n",
    "le = LabelEncoder()\n",
    "y_present_enc = le.fit_transform(y_present)\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_present_enc, y_present_enc,test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f721f2",
   "metadata": {},
   "source": [
    "This section defines functions for KNN classification:\n",
    "\n",
    "- `get_neighbors`: Calculates distances between the test row and all training set rows to identify the nearest neighbors based on the specified number `num_neighbors`.\n",
    "\n",
    "- 'predict_classification': Predicts the class label for a test row by determining the most common class label among its nearest neighbors.\n",
    "\n",
    "Using these functions, predictions are generated for the test set with num_neighbors set to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1387501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN functions\n",
    "def get_neighbors(X_train, test_row, num_neighbors):\n",
    "    distances = np.linalg.norm(X_train - test_row, axis=1)\n",
    "    sorted_row_indices=np.argsort(distances)\n",
    "    return sorted_row_indices[:num_neighbors]\n",
    "\n",
    "def predict_classification(X_train, y_train, test_row, num_neighbors):\n",
    "    neighbor_indices = get_neighbors(X_train, test_row, num_neighbors)\n",
    "    output_values = y_train[neighbor_indices]\n",
    "    output_values_counter= Counter(output_values)\n",
    "    prediction = output_values_counter.most_common(1)[0][0]\n",
    "    return prediction\n",
    "\n",
    "num_neighbors = 3\n",
    "predictions = [predict_classification(X_train, y_train, row, num_neighbors) for row in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea30a9",
   "metadata": {},
   "source": [
    "In this section, missing values in the 'stalk-root' column are predicted and imputed. The process involves preparing features from the missing data and transforming them using a pre-fitted encoder. Predictions for the encoded features are made using KNN, and these predicted labels are decoded into their original categories. Unique values along with their counts are then displayed, providing insights into the distribution of imputed values. The imputed values are assigned back into the original dataset, completing the imputation process. Finally, the remaining count of missing values is printed, confirming the success of the imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b7e580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 1904\n",
      "c: 60\n",
      "e: 516\n",
      "Unique values of missing_values: 0\n"
     ]
    }
   ],
   "source": [
    "# Predicting missing values for 'stalk-root' column\n",
    "X_missing = missing_data.drop(columns=['stalk-root'])\n",
    "X_missing_enc = enc.transform(X_missing)\n",
    "\n",
    "# Predicting encoded labels\n",
    "missing_labels_enc = [predict_classification(X_train, y_train, row, num_neighbors)for row in X_missing_enc]\n",
    "\n",
    "# Decoding labels into original categories\n",
    "missing_values_imputed = le.inverse_transform(missing_labels_enc)\n",
    " \n",
    "missing_values = list(missing_values_imputed) # Generate list missing_values\n",
    "unique_values, counts = np.unique(missing_values, return_counts=True)\n",
    "\n",
    "for value, count in zip(unique_values, counts): # Display unique values and counts\n",
    "    print(f\"{value}: {count}\")\n",
    "\n",
    "missing_data_indices = missing_data.index # Impute missing values back into the original dataset\n",
    "for i, index in enumerate(missing_data_indices):\n",
    "    data.at[index, 'stalk-root'] = missing_values[i]\n",
    "\n",
    "# Print the unique values of missing_values along with the count of each value\n",
    "print(f\"Unique values of missing_values: {data['stalk-root'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ae7aa",
   "metadata": {},
   "source": [
    "**Graded Concept Question #1:** Why don’t we one-hot encode the response data to train the KNN model instead? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b61d56",
   "metadata": {},
   "source": [
    "One-hot encoding was not utilized for the response data in KNN models because it would transform the categorical targets into binary columns. Using one-hot encoding for the target variable won't preserve the proximity necessary for KNN's operation. Label encoding maintains the categorical items in a single-column format for KNN's classification strategy which is based on feature proximity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a2f52",
   "metadata": {},
   "source": [
    "In this section, the dataset undergoes encoding for modeling:\n",
    "\n",
    "- Features (`X`) and the response variable (`y`) are isolated.\n",
    "- Features are one-hot encoded using `OneHotEncoder`, ensuring categorical variables are represented as binary vectors.\n",
    "- The response variable is label encoded with `LabelEncoder` to convert categorical labels into numerical values.\n",
    "- The dataset is divided into training and testing sets using `train_test_split`, with 20% allocated for testing and a specified random state for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6047a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding dataset\n",
    "X = data.drop(columns=['class']) #Features\n",
    "y = data['class'] #Response variable\n",
    "\n",
    "# One-hot encode features\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_enc = enc.fit_transform(X)\n",
    "\n",
    "#Label encode response variable\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cb62a",
   "metadata": {},
   "source": [
    "In this section, two classifiers, RandomForestClassifier and LogisticRegression, are instantiated and trained:\n",
    "\n",
    "- RandomForestClassifier is instantiated with a specified random state.\n",
    "- Training time for RandomForestClassifier is measured using `%time`.\n",
    "- LogisticRegression is instantiated with a specified random state.\n",
    "- Training time for LogisticRegression is measured using `%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063e6285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 495 ms, sys: 13.2 ms, total: 508 ms\n",
      "Wall time: 515 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "%time rf.fit(X_train, y_train)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6e27a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 313 ms, sys: 22.9 ms, total: 336 ms\n",
      "Wall time: 199 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate LogisticRegression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "%time lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0dd57f",
   "metadata": {},
   "source": [
    "**Graded Concept Question #2:** Could we train these two models by one-hot encoding the response data instead, being careful to specify that the drop parameter of the OneHotEncoder class is set to ‘first’? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec519c",
   "metadata": {},
   "source": [
    "One-hot encoding the response in classification tasks like predicting mushroom edibility is unusual. Logistic Regression and RandomForest handle categorical targets without one-hot encoding. For input features without ordinal relationships, one-hot encoding is beneficial, but for the response variable, direct label encoding is simpler and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6af5ce",
   "metadata": {},
   "source": [
    "In this section, predictions are made for both RandomForestClassifier and LogisticRegression models on the test set:\n",
    "\n",
    "- Predictions for RandomForestClassifier `rf_pred` and LogisticRegression `lr_pred` are generated using the `predict` method.\n",
    "- Accuracy scores `rf_acc` and `lr_acc` are calculated using `accuracy_score` by comparing predicted labels with true labels from the test set.\n",
    "- Precision scores `rf_precision` and `lr_precision` are calculated using `precision_score`, representing the proportion of correctly predicted positive instances among all instances predicted as positive.\n",
    "- Recall scores `rf_recall` and `lr_recall` are calculated using `recall_score`, representing the proportion of correctly predicted positive instances among all actual positive instances.\n",
    "\n",
    "These metrics provide insights into the performance of both models in terms of accuracy, precision, and recall.\n",
    "The returned values indicate that both models attained 100% accuracy, precision, and recall on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c373ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test,lr_pred)\n",
    "\n",
    "rf_precision = precision_score(y_test, rf_pred) # RandomForest precision score\n",
    "rf_recall = recall_score(y_test, rf_pred) # RandomForest recall score\n",
    "\n",
    "lr_precision = precision_score(y_test, lr_pred) # LogisticRegression precision score\n",
    "lr_recall = recall_score(y_test, lr_pred) # LogisticRegression recall score\n",
    "\n",
    "(rf_acc, lr_acc, rf_precision, lr_precision, rf_recall, lr_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b73ab",
   "metadata": {},
   "source": [
    "In this section, PCA (Principal Component Analysis) is applied to reduce the dimensionality of the training data:\n",
    "\n",
    "- PCA is instantiated with a specified target explained variance ratio of 95% and a random state for reproducibility.\n",
    "- PCA is fitted to the training data `X_train` to learn the transformation.\n",
    "- The original number of features `org_shape`, the reduced number of features after PCA transformation `reduced_shape`, and the percentage reduction in dimensionality `precent_reduced` are calculated and displayed. This provides insights into the effectiveness of dimensionality reduction achieved by PCA.\n",
    "\n",
    "After the reduction, the number of dimensions of the training set was reduced by approximately 65%. There are 40 features after reducing dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c00bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 40, 65.51724137931035)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca =PCA(n_components=.95, random_state=42) # Instantiate PCA\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train) # Fit PCA\n",
    "\n",
    "# Calculation of precent reduction\n",
    "org_shape = X_train.shape[1]\n",
    "reduced_shape = X_train_pca.shape[1]\n",
    "precent_reduced = (1 -reduced_shape / org_shape) * 100\n",
    "\n",
    "(org_shape, reduced_shape, precent_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824bd24",
   "metadata": {},
   "source": [
    "In this section, the test set is prepared using PCA transformation:\n",
    "\n",
    "- The test set `X_test` is transformed into the reduced feature space using the previously fitted PCA model `pca`.\n",
    "\n",
    "Then, models are instantiated and trained on the reduced dataset:\n",
    "\n",
    "- RandomForestClassifier `rf_pca` is instantiated with a specified random state.\n",
    "- Training time for RandomForestClassifier on the reduced dataset is measured using `%time`.\n",
    "- LogisticRegression `lr_pca` is instantiated with a specified random state.\n",
    "- Training time for LogisticRegression on the reduced dataset is measured using `%time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64fc77eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 50.7 ms, total: 3.47 s\n",
      "Wall time: 3.41 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pca = pca.transform(X_test) # Preparing test set\n",
    "\n",
    "#Instantiate and train RandomForestCLassifier on the reduced dataset\n",
    "rf_pca = RandomForestClassifier(random_state=42)\n",
    "%time rf_pca.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c043ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88.9 ms, sys: 8.69 ms, total: 97.5 ms\n",
      "Wall time: 78.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train LogisticRegression model on reduced data\n",
    "lr_pca = LogisticRegression(random_state=42)\n",
    "%time lr_pca.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7988f5e",
   "metadata": {},
   "source": [
    "In this section, predictions are made using the trained RandomForestClassifier `rf_pca` and LogisticRegression `lr_pca` models on the reduced test set:\n",
    "\n",
    "- Predictions for both models are generated using the `predict` method on the reduced test set `X_test_pca`.\n",
    "- Accuracy scores `rf_pca_acc` and `lr_pca_acc`, precision scores `rf_pca_precision` and `lr_pca_precision`, and recall scores `rf_pca_recall` and `lr_pca_recall` are calculated for both models using the corresponding metrics functions from scikit-learn.\n",
    "\n",
    "These metrics provide insights into the performance of the models trained on the reduced dataset in terms of accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7992fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pca_pred = rf_pca.predict(X_test_pca)\n",
    "lr_pca_pred = lr_pca.predict(X_test_pca)\n",
    "\n",
    "rf_pca_acc = accuracy_score(y_test,rf_pca_pred)\n",
    "rf_pca_precision = precision_score(y_test, rf_pca_pred)\n",
    "rf_pca_recall = recall_score(y_test, rf_pca_pred)\n",
    "\n",
    "lr_pca_acc = accuracy_score(y_test, lr_pca_pred)\n",
    "lr_pca_precision = precision_score(y_test, lr_pca_pred)\n",
    "lr_pca_recall = recall_score(y_test, lr_pca_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a4edae",
   "metadata": {},
   "source": [
    "In this section, I present a structured comparison of model performance and training times for both the full data and PCA reduced datasets:\n",
    "\n",
    "- **Structured Data**: I organize the data into a structured format with columns representing different aspects of model evaluation, including model type, performance metrics (accuracy, precision, recall), and training time.\n",
    "- **Model Performance**: For each model type (RandomForest and LogisticRegression), I report accuracy, precision, and recall scores for both the full data and PCA reduced datasets. These metrics provide insights into how well the models perform in terms of correctly predicting outcomes and capturing true positives.\n",
    "- **Training Time**: I also include the training time for each model type on both datasets. This metric indicates the computational efficiency of each model in terms of the time required to train on the given dataset size.\n",
    "- **DataFrame Presentation**: The structured data is presented in a DataFrame format for clarity and easy comparison. Each row represents a specific aspect of model evaluation, facilitating a side-by-side comparison of metrics across different models and datasets.\n",
    "\n",
    "Overall, this structured comparison provides a comprehensive overview of model performance and computational efficiency for both the full data and PCA reduced datasets, aiding in the decision-making process for model selection and optimization. I utilized the `~` symbol to indicate the approximate times because I was unable to figure out how to populate the total time in the structured comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d20ab2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Model      Item Full Data PCA Reduced\n",
      "      RandomForest  Accuracy       1.0         1.0\n",
      "                   Precision       1.0         1.0\n",
      "                      Recall       1.0         1.0\n",
      "                        Time   ~502 ms     ~3.32 s\n",
      "LogisticRegression  Accuracy       1.0    0.995692\n",
      "                   Precision       1.0    0.994891\n",
      "                      Recall       1.0    0.996164\n",
      "                        Time   ~289 ms    ~97.5 ms\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Model\": [\"RandomForest\", \"\", \"\", \"\", \"LogisticRegression\", \"\", \"\", \"\"],\n",
    "    \"Item\": [\"Accuracy\", \"Precision\", \"Recall\", \"Time\", \"Accuracy\", \"Precision\", \"Recall\", \"Time\"],\n",
    "    \"Full Data\": [rf_acc, rf_precision, rf_recall, '~502 ms', \n",
    "                  lr_acc, lr_precision, lr_recall, '~289 ms'],\n",
    "    \"PCA Reduced\": [rf_pca_acc, rf_pca_precision, rf_pca_recall, '~3.32 s',\n",
    "                    lr_pca_acc, lr_pca_precision, lr_pca_recall, '~97.5 ms']\n",
    "}\n",
    "\n",
    "# Convert the structured data into a DataFrame\n",
    "structured_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame without the index\n",
    "print(structured_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919814b1",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In considering the potential for overfitting, I examined the models' performance on both the full and PCA-reduced datasets. By comparing metrics like accuracy, precision, and recall between the two, I assessed whether the models were overfitting. After evaluating the models, I drew conclusions based on their performance. The full dataset models generally achieved higher scores, but the PCA-reduced models showed reduced execution times, indicating a trade-off between performance and computational efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
